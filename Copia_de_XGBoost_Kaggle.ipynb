{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "C0h1aNElnil0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "b277f332-ab30-4396-de44-7292a11715c5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ef884030d8c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m  \u001b[0;31m#GBM algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m   \u001b[0;31m#Additional scklearn functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_search\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m   \u001b[0;31m# Perforing grid search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'cross_validation' from 'sklearn' (/usr/local/lib/python3.7/dist-packages/sklearn/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "#Elaborado Manuel Guerrero\n",
        "#Colaboradores: Abdel\n",
        "# pandas\n",
        "import pandas as pd\n",
        "from pandas import Series,DataFrame\n",
        "\n",
        "# numpy, matplotlib, seaborn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "%matplotlib inline\n",
        "\n",
        "#!pip install sklearn\n",
        "\n",
        "import xgboost as xgb  #GBM algorithm\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
        "from sklearn.grid_search import GridSearchCV   # Perforing grid search\n",
        "\n",
        "from IPython.display import display\n",
        "\n",
        "# remove warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwwlQdfknil6"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv('data/new_train.csv')\n",
        "test_data = pd.read_csv('data/new_test.csv')\n",
        "\n",
        "for i in train_data.index:    \n",
        "    if train_data.loc[i,'LotArea'] >= 20000:      #Remover 5 datos atipicos en lot Area, Sugerido por el creador del dataset\n",
        "        train_data.drop(index = i, axis = 'index', inplace=True)\n",
        "\n",
        "print(train_data.shape())\n",
        "display(train_data.head(1))\n",
        "# display(train_data.info())\n",
        "\n",
        "print test_data.shape\n",
        "display(test_data.head(1))\n",
        "# display(test_data.info())\n",
        "train_length = train_data.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbZx192Nnil_"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def common_num_range(start,stop,step):\n",
        "    \n",
        "    startlen = stoplen = steplen = 0\n",
        "    if '.' in str(start):\n",
        "        startlen = len(str(start)) - str(start).index('.') - 1\n",
        "    if '.' in str(stop):\n",
        "        stoplen = len(str(stop)) - str(stop).index('.') - 1\n",
        "    if '.' in str(step)\n",
        "        steplen = len(str(step)) - str(step).index('.') - 1\n",
        "    \n",
        "    maxlen = startlen\n",
        "    if stoplen > maxlen:\n",
        "        maxlen = stoplen\n",
        "    if steplen > maxlen:\n",
        "        maxlen = steplen\n",
        "    \n",
        "    power = math.pow(10, maxlen)\n",
        "    \n",
        "    if startlen == 0 and stoplen == 0 and steplen == 0:\n",
        "        return range(start, stop, step)\n",
        "    else:\n",
        "        return [num / power for num in range(int(start*power), int(stop*power), int(step*power))]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bNOSbHRlnimB"
      },
      "outputs": [],
      "source": [
        "train_id = train_data['Id']\n",
        "train_Y = train_data['SalePrice']\n",
        "train_data.drop(['Id', 'SalePrice'], axis=1, inplace=True)\n",
        "train_X = train_data\n",
        "\n",
        "test_Id = test_data['Id']\n",
        "test_data.drop('Id', axis=1, inplace=True)\n",
        "test_X = test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avrvSmhknimC"
      },
      "outputs": [],
      "source": [
        "# formatting for xgb\n",
        "dtrain = xgb.DMatrix(train_X, label=train_Y)\n",
        "dtest = xgb.DMatrix(test_X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64GrPqHqnimD"
      },
      "source": [
        "# XGBoost  & Parameter Tuning\n",
        "\n",
        "Ref: [Complete Guide to Parameter Tuning in XGBoost](https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "n88JTAo2nimH"
      },
      "source": [
        "## Parameters Tuning Plan\n",
        "\n",
        "The overall parameters can be divided into 3 categories:\n",
        "\n",
        "1. General Parameters: Guide the overall functioning\n",
        "2. Booster Parameters: Guide the individual booster (tree/regression) at each step\n",
        "3. Learning Task Parameters: Guide the optimization performed\n",
        "\n",
        "In `XGBRegressor`:\n",
        "```\n",
        "class xgboost.XGBRegressor(max_depth=3, learning_rate=0.1, n_estimators=100, silent=True, objective='reg:linear', nthread=-1, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, colsample_bytree=1, colsample_bylevel=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, base_score=0.5, seed=0, missing=None)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "kKWI6lqXnimI"
      },
      "outputs": [],
      "source": [
        "# The error metric: RMSE on the log of the sale prices.\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def rmse(y_true, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5N5MQemBnimJ"
      },
      "outputs": [],
      "source": [
        "def model_cross_validate(xgb_regressor, cv_paramters, dtrain, cv_folds = 5,\n",
        "              early_stopping_rounds = 50, perform_progress=False):\n",
        "    \"\"\"\n",
        "    xgb model cross validate to choose best param from giving cv_paramters.\n",
        "    \n",
        "    @param cv_paramters:dict,where to choose best param. {'param':[1,2,3]}\n",
        "    @param dtrain:xgboost.DMatrix, training data formatted for xgb\n",
        "    @param early_stopping_rounds: Activates early stopping.Stop when perfomance \n",
        "                                  does not improve for some rounds\n",
        "    \"\"\"\n",
        "    # get initial parameters\n",
        "    xgb_param = xgb_regressor.get_xgb_params()\n",
        "    \n",
        "    # save best param\n",
        "    best_params = {}\n",
        "    best_cvresult = None\n",
        "    min_mean_rmse = float(\"inf\")\n",
        "    \n",
        "    for param, values in cv_paramters.items():\n",
        "        print '===========Tuning paramter:',param,'==========='\n",
        "        best_param = values[0]\n",
        "        for value in values:\n",
        "            # set the param's value\n",
        "            xgb_param[param] = value\n",
        "            \n",
        "            # cv to tune param from values\n",
        "            cvresult = xgb.cv(xgb_param, dtrain, num_boost_round=xgb_param['n_estimators'], \n",
        "                              nfold=cv_folds, metrics='rmse', \n",
        "                              early_stopping_rounds=early_stopping_rounds)\n",
        "\n",
        "            # calcuate the mean of several final rmses\n",
        "            round_count = cvresult.shape[0]\n",
        "            mean_rmse = cvresult.loc[round_count-11:round_count-1,'test-rmse-mean'].mean()\n",
        "            \n",
        "            if perform_progress:\n",
        "                std_rmse = cvresult.loc[round_count-11:round_count-1,'test-rmse-std'].mean()\n",
        "\n",
        "                if isinstance(value, int):\n",
        "                    print \"%s=%d CV RMSE : Mean = %.7g | Std = %.7g\" % (param, value, mean_rmse, std_rmse)\n",
        "                else:\n",
        "                    print \"%s=%f CV RMSE : Mean = %.7g | Std = %.7g\" % (param, value, mean_rmse, std_rmse)\n",
        "            \n",
        "            if mean_rmse < min_mean_rmse:\n",
        "                best_param = value\n",
        "                best_cvresult = cvresult\n",
        "                min_mean_rmse = mean_rmse\n",
        "        \n",
        "        best_params[param] = best_param\n",
        "        # set best param value for xgb params, important\n",
        "        xgb_param[param] = best_param\n",
        "        print \"best \", param, \" = \", best_params[param]\n",
        "    \n",
        "    return best_params, min_mean_rmse, best_cvresult\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "vsjAlcernimL"
      },
      "outputs": [],
      "source": [
        "def model_fit(xgb_regressor, train_x, train_y, performCV=True, \n",
        "              printFeatureImportance=True, cv_folds=5):\n",
        "    \n",
        "    # Perform cross-validation\n",
        "    if performCV:\n",
        "        xgb_param = xgb_regressor.get_xgb_params()\n",
        "        cvresult = xgb.cv(xgb_param, dtrain, num_boost_round=xgb_param['n_estimators'], \n",
        "                              nfold=cv_folds, metrics='rmse', \n",
        "                              early_stopping_rounds=50)\n",
        "        round_count = cvresult.shape[0]\n",
        "        mean_rmse = cvresult.loc[round_count-11:round_count-1,'test-rmse-mean'].mean()\n",
        "        std_rmse = cvresult.loc[round_count-11:round_count-1,'test-rmse-std'].mean()\n",
        "        \n",
        "        print \"CV RMSE : Mean = %.7g | Std = %.7g\" % (mean_rmse, std_rmse)\n",
        "        \n",
        "    # fir the train data\n",
        "    xgb_regressor.fit(train_x, train_y)\n",
        "    \n",
        "    # Predict training set\n",
        "    train_predictions = xgb_regressor.predict(train_x)\n",
        "    mse = rmse(train_y, train_predictions)\n",
        "    print(\"Train RMSE: %.7f\" % mse)\n",
        "    \n",
        "    # Print Feature Importance\n",
        "    if printFeatureImportance:\n",
        "        feature_importances = pd.Series(xgb_regressor.feature_importances_, train_x.columns.values)\n",
        "        feature_importances = feature_importances.sort_values(ascending=False)\n",
        "        feature_importances= feature_importances.head(40)\n",
        "        feature_importances.plot(kind='bar', title='Feature Importances')\n",
        "        plt.ylabel('Feature Importance Score')\n",
        "    \n",
        "    return xgb_regressor, feature_importances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKM7-tVGnimM"
      },
      "source": [
        "Baseline XGBRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7_pttb2nimO"
      },
      "outputs": [],
      "source": [
        "xgb_regressor = XGBRegressor(seed=10)\n",
        "xgb_regressor, feature_importances = model_fit(xgb_regressor,train_X, train_Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsjGmo-VnimP"
      },
      "source": [
        "### 1. Choose a relatively high learning_rate,optimum n_estimators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzRcflGAnimQ"
      },
      "outputs": [],
      "source": [
        "param_test = {'n_estimators':range(300,400,10)}\n",
        "\n",
        "xgb_regressor = XGBRegressor(\n",
        "                learning_rate =0.05,\n",
        "\n",
        "                max_depth=5,\n",
        "                min_child_weight=1,\n",
        "                gamma=0,\n",
        "                subsample=0.8,\n",
        "                colsample_bytree=0.8,\n",
        "                reg_lambda = 0.1,\n",
        "                reg_alpha = 0.1,\n",
        "                scale_pos_weight=1,\n",
        "                objective= 'reg:linear',\n",
        "                seed=10)\n",
        "\n",
        "best_param, min_mean_rmse, best_cvresult = \\\n",
        "                model_cross_validate(xgb_regressor, param_test, dtrain, perform_progress=True)\n",
        "\n",
        "print 'cross-validate best params:', best_param\n",
        "print 'cross-validate min_mean_rmse:', min_mean_rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cnur7QZnimR"
      },
      "outputs": [],
      "source": [
        "xgb_regressor = XGBRegressor(\n",
        "                learning_rate =0.05,\n",
        "                n_estimators = 300,\n",
        "\n",
        "                max_depth=5,\n",
        "                min_child_weight=1,\n",
        "                gamma=0,\n",
        "                subsample=0.8,\n",
        "                colsample_bytree=0.8,\n",
        "                reg_lambda = 0.1,\n",
        "                reg_alpha = 0.1,\n",
        "                scale_pos_weight=1,\n",
        "                objective= 'reg:linear',\n",
        "                seed=10)\n",
        "\n",
        "xgb_regressor, feature_importances = model_fit(xgb_regressor,train_X, train_Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "P-eLVM9unimT"
      },
      "source": [
        "### 2.Fix learning rate and number of estimators for tuning tree-based parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "5L8h40kjnimT"
      },
      "source": [
        "Tune `max_depth` and `min_child_weight`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvPjNNxtnimU"
      },
      "outputs": [],
      "source": [
        "param_test = {'max_depth':range(1,6,1),\n",
        "               'min_child_weight':common_num_range(1,2,0.1)}\n",
        "\n",
        "xgb_regressor = XGBRegressor(\n",
        "                learning_rate =0.05,\n",
        "                n_estimators = 300,\n",
        "    \n",
        "                gamma=0,\n",
        "                subsample=0.8,\n",
        "                colsample_bytree=0.8,\n",
        "                reg_lambda = 0.1,\n",
        "                reg_alpha = 0.1,\n",
        "                scale_pos_weight=1,\n",
        "                objective= 'reg:linear',\n",
        "                seed=10)\n",
        "\n",
        "best_param, min_mean_rmse, best_cvresult = \\\n",
        "                model_cross_validate(xgb_regressor, param_test, dtrain, perform_progress=True)\n",
        "\n",
        "print 'cross-validate best params:', best_param\n",
        "print 'cross-validate min_mean_rmse:', min_mean_rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pX6j-VjGnimV"
      },
      "outputs": [],
      "source": [
        "xgb_regressor = XGBRegressor(\n",
        "                learning_rate =0.05,\n",
        "                n_estimators = 300,\n",
        "                max_depth=3,\n",
        "                min_child_weight=1.1,\n",
        "    \n",
        "                gamma=0,\n",
        "                subsample=0.8,\n",
        "                colsample_bytree=0.8,\n",
        "                reg_lambda = 0.1,\n",
        "                reg_alpha = 0.1,\n",
        "                scale_pos_weight=1,\n",
        "                objective= 'reg:linear',\n",
        "                seed=10)\n",
        "\n",
        "xgb_regressor, feature_importances = model_fit(xgb_regressor,train_X, train_Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "1a8ODPCfnimX"
      },
      "source": [
        "Tune `gamma`,Minimum loss reduction required to make a further partition on a leaf node of the tree. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wE13cVcmnimY"
      },
      "outputs": [],
      "source": [
        "param_test = {'gamma':[0, 0.1, 0.01, 0.001,0.0001, 0.00001]}\n",
        "\n",
        "xgb_regressor = XGBRegressor(\n",
        "                learning_rate =0.05,\n",
        "                n_estimators = 300,\n",
        "                max_depth=3,\n",
        "                min_child_weight=1.1,\n",
        "    \n",
        "                subsample=0.8,\n",
        "                colsample_bytree=0.8,\n",
        "                reg_lambda = 0.1,\n",
        "                reg_alpha = 0.1,\n",
        "                scale_pos_weight=1,\n",
        "                objective= 'reg:linear',\n",
        "                seed=10)\n",
        "\n",
        "best_param, min_mean_rmse, best_cvresult = \\\n",
        "                model_cross_validate(xgb_regressor, param_test, dtrain, perform_progress=True)\n",
        "\n",
        "print 'cross-validate best params:', best_param\n",
        "print 'cross-validate min_mean_rmse:', min_mean_rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R75yRP0animZ"
      },
      "outputs": [],
      "source": [
        "xgb_regressor = XGBRegressor(\n",
        "                learning_rate =0.05,\n",
        "                n_estimators = 300,\n",
        "                max_depth=3,\n",
        "                min_child_weight=1.1,\n",
        "                gamma=0.01,\n",
        "    \n",
        "                subsample=0.8,\n",
        "                colsample_bytree=0.8,\n",
        "                reg_lambda = 0.1,\n",
        "                reg_alpha = 0.1,\n",
        "                scale_pos_weight=1,\n",
        "                objective= 'reg:linear',\n",
        "                seed=10)\n",
        "\n",
        "xgb_regressor, feature_importances = model_fit(xgb_regressor,train_X, train_Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "Ht5AjFYWnima"
      },
      "source": [
        "Tune `subsample` and `colsample_bytree`\n",
        "\n",
        "- subsample : Subsample ratio of the training instance.\n",
        "- colsample_bytree : Subsample ratio of columns when constructing each tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "3JelbYrznimb"
      },
      "outputs": [],
      "source": [
        "param_test = {'subsample':common_num_range(0.6, 0.9, 0.01),\n",
        "               'colsample_bytree':common_num_range(0.6, 0.9, 0.01)}\n",
        "\n",
        "xgb_regressor = XGBRegressor(\n",
        "                learning_rate =0.05,\n",
        "                n_estimators = 300,\n",
        "                max_depth=3,\n",
        "                min_child_weight=1.1,\n",
        "                gamma=0.01,\n",
        "    \n",
        "                reg_lambda = 0.1,\n",
        "                reg_alpha = 0.1,\n",
        "                scale_pos_weight=1,\n",
        "                objective= 'reg:linear',\n",
        "                seed=10)\n",
        "\n",
        "best_param, min_mean_rmse, best_cvresult = \\\n",
        "                model_cross_validate(xgb_regressor, param_test, dtrain, perform_progress=True)\n",
        "\n",
        "print 'cross-validate best params:', best_param\n",
        "print 'cross-validate min_mean_rmse:', min_mean_rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "K46ghWNknimc"
      },
      "outputs": [],
      "source": [
        "xgb_regressor = XGBRegressor(\n",
        "                learning_rate =0.05,\n",
        "                n_estimators = 300,\n",
        "                max_depth=3,\n",
        "                min_child_weight=1.1,\n",
        "                gamma=0.01,\n",
        "                subsample=0.72,\n",
        "                colsample_bytree=0.89,\n",
        "    \n",
        "                reg_lambda = 0.1,\n",
        "                reg_alpha = 0.1,\n",
        "                scale_pos_weight=1,\n",
        "                objective= 'reg:linear',\n",
        "                seed=10)\n",
        "\n",
        "xgb_regressor, feature_importances = model_fit(xgb_regressor,train_X, train_Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "lglIvQRhnimd"
      },
      "outputs": [],
      "source": [
        "param_test2 = {'reg_lambda':common_num_range(0.55, 0.65, 0.01),\n",
        "               'reg_alpha':common_num_range(0.45, 0.6, 0.01)}\n",
        "\n",
        "xgb_regressor = XGBRegressor(\n",
        "                learning_rate =0.05,\n",
        "                n_estimators = 300,\n",
        "                max_depth=3,\n",
        "                min_child_weight=1.1,\n",
        "                gamma=0.01,\n",
        "                subsample=0.72,\n",
        "                colsample_bytree=0.89,\n",
        "    \n",
        "                scale_pos_weight=1,\n",
        "                objective= 'reg:linear',\n",
        "                seed=10)\n",
        "\n",
        "best_param, min_mean_rmse, best_cvresult = \\\n",
        "                model_cross_validate(xgb_regressor, param_test2, dtrain, perform_progress=True)\n",
        "\n",
        "print 'cross-validate best params:', best_param\n",
        "print 'cross-validate min_mean_rmse:', min_mean_rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sU_SF5Lnimf"
      },
      "outputs": [],
      "source": [
        "xgb_regressor = XGBRegressor(\n",
        "                learning_rate =0.05,\n",
        "                n_estimators = 300,\n",
        "                max_depth=3,\n",
        "                min_child_weight=1.1,\n",
        "                gamma=0.01,\n",
        "                subsample=0.72,\n",
        "                colsample_bytree=0.89,\n",
        "                reg_lambda = 0.61,\n",
        "                reg_alpha = 0.53,\n",
        "    \n",
        "                scale_pos_weight=1,\n",
        "                objective= 'reg:linear',\n",
        "                seed=10)\n",
        "\n",
        "xgb_regressor, feature_importances = model_fit(xgb_regressor,train_X, train_Y)                                           "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jg6mCZudnimg"
      },
      "outputs": [],
      "source": [
        "xgb_regressor = XGBRegressor(\n",
        "                learning_rate =0.01,\n",
        "                n_estimators = 4000,\n",
        "                max_depth=3,\n",
        "                min_child_weight=1.1,\n",
        "                gamma=0.01,\n",
        "                subsample=0.72,\n",
        "                colsample_bytree=0.89,\n",
        "                reg_lambda = 0.61,\n",
        "                reg_alpha = 0.53,\n",
        "    \n",
        "                scale_pos_weight=1,\n",
        "                objective= 'reg:linear',\n",
        "                seed=10)\n",
        "\n",
        "xgb_regressor, feature_importances = model_fit(xgb_regressor,train_X, train_Y)                                           "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxknC4Otnimh"
      },
      "source": [
        "Final paramters:\n",
        "\n",
        "```\n",
        "xgb_regressor = XGBRegressor(\n",
        "                learning_rate =0.01,\n",
        "                n_estimators = 4000,\n",
        "                max_depth=3,\n",
        "                min_child_weight=1.1,\n",
        "                gamma=0.01,\n",
        "                subsample=0.72,\n",
        "                colsample_bytree=0.89,\n",
        "                reg_lambda = 0.61,\n",
        "                reg_alpha = 0.53,\n",
        "    \n",
        "                scale_pos_weight=1,\n",
        "                objective= 'reg:linear',\n",
        "                seed=10)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFiR2jpQnimh"
      },
      "outputs": [],
      "source": [
        "xgb_predictions = xgb_regressor.predict(test_X)\n",
        "xgb_predictions = np.expm1(xgb_predictions)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "        \"Id\": test_Id,\n",
        "        \"SalePrice\": xgb_predictions\n",
        "    })\n",
        "\n",
        "submission.to_csv(\"result/xgb_param_tune_predictions_2_13.csv\", index=False)\n",
        "\n",
        "print \"Done.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nqx4VHEInimi"
      },
      "source": [
        "# Model Voting\n",
        "\n",
        "Ridge, ElasticNet, Lasso, XGBRegressor model voting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxnO30KXnimj"
      },
      "outputs": [],
      "source": [
        "from sklearn.cross_validation import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_X, train_Y, \n",
        "                                                    test_size=0.4, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuKxnSVmnimj"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Ridge, ElasticNet, Lasso\n",
        "\n",
        "def simple_model_cross_validate(alphas, Model, model_name):\n",
        "    min_rmse = float('inf')\n",
        "    best_alpha = None\n",
        "    for alpha in alphas:\n",
        "        model = Model(alpha, max_iter=50000).fit(X_train, y_train)\n",
        "        model_rmse = rmse(model.predict(X_test), y_test)\n",
        "        if model_rmse < min_rmse:\n",
        "            best_alpha = alpha\n",
        "            min_rmse = model_rmse\n",
        "\n",
        "    print model_name, 'best_alpha = ', best_alpha, 'min_rmse = ', min_rmse\n",
        "\n",
        "alphas = common_num_range(0.0001, 0.002, 0.0001)\n",
        "simple_model_cross_validate(alphas, Lasso, 'Lasso')\n",
        "simple_model_cross_validate(alphas, ElasticNet, 'ElasticNet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZcGVgMcnimk"
      },
      "outputs": [],
      "source": [
        "alphas = common_num_range(25, 50, 1)\n",
        "simple_model_cross_validate(alphas, Ridge, 'Ridge')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Cdo39gfxniml"
      },
      "outputs": [],
      "source": [
        "lasso_model = Lasso(alpha=0.0009, max_iter=50000).fit(X_train, y_train)\n",
        "elastic_net_model = ElasticNet(alpha=0.0019, max_iter=50000).fit(X_train, y_train)\n",
        "ridge_model = Ridge(alpha=41, max_iter=50000).fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9QvbrJTLnimm"
      },
      "outputs": [],
      "source": [
        "lasso_predictions = lasso_model.predict(test_X)\n",
        "lasso_predictions = np.expm1(lasso_predictions)\n",
        "\n",
        "ridge_predictions = ridge_model.predict(test_X)\n",
        "ridge_predictions = np.expm1(ridge_predictions)\n",
        "\n",
        "elastic_net_predictions = elastic_net_model.predict(test_X)\n",
        "elastic_net_predictions = np.expm1(elastic_net_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQDrrn_9nimm"
      },
      "outputs": [],
      "source": [
        "predictions = (lasso_predictions + ridge_predictions + elastic_net_predictions + xgb_predictions) / 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuKNYLTLnimn"
      },
      "outputs": [],
      "source": [
        "plt.subplot(221)\n",
        "plt.plot(lasso_predictions, c=\"blue\")  # 0.12818\n",
        "plt.title('lasso 0.12818')\n",
        "plt.subplot(222)\n",
        "plt.plot(elastic_net_predictions, c=\"yellow\")  # 0.12908\n",
        "plt.title('elastic_net 0.12908')\n",
        "plt.subplot(223)\n",
        "plt.plot(ridge_predictions, c=\"pink\")  # 0.13161\n",
        "plt.title('ridge 0.13161')\n",
        "plt.subplot(224)\n",
        "plt.plot(xgb_predictions, c=\"green\")  # 0.12167\n",
        "plt.title('xgb 0.12167')\n",
        "plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
        "plt.show()\n",
        "plt.subplot(111)\n",
        "plt.plot(predictions, c=\"red\")  # 0.12419\n",
        "plt.title('4 model vote 0.12419')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2YGM6VOnimo"
      },
      "outputs": [],
      "source": [
        "# outlier data\n",
        "np.argwhere(lasso_predictions == lasso_predictions[lasso_predictions > 700000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "aT0toUsCnimp"
      },
      "outputs": [],
      "source": [
        "# convert outlier data to xgb_predictions[1089]\n",
        "lasso_predictions[1089] =  xgb_predictions[1089]\n",
        "ridge_predictions[1089] =  xgb_predictions[1089]\n",
        "elastic_net_predictions[1089] =  xgb_predictions[1089]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "PLhhUxVnnimp"
      },
      "outputs": [],
      "source": [
        "lasso_score = 1-0.12818\n",
        "ridge_score = 1-0.13161\n",
        "elastic_net_score = 1-0.12908\n",
        "xgb_score = 1-0.12167\n",
        "total_score = lasso_score + ridge_score + elastic_net_score + xgb_score\n",
        "predictions = (lasso_score / total_score) * lasso_predictions + \\\n",
        "              (ridge_score / total_score) * ridge_predictions + \\\n",
        "              (elastic_net_score / total_score) * elastic_net_predictions + \\\n",
        "              (xgb_score / total_score) * xgb_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "pRS90Pirnimq"
      },
      "outputs": [],
      "source": [
        "plt.subplot(221)\n",
        "plt.plot(lasso_predictions, c=\"blue\")  # 0.12818\n",
        "plt.title('lasso 0.12818')\n",
        "plt.subplot(222)\n",
        "plt.plot(elastic_net_predictions, c=\"yellow\")  # 0.12908\n",
        "plt.title('elastic_net 0.12908')\n",
        "plt.subplot(223)\n",
        "plt.plot(ridge_predictions, c=\"pink\")  # 0.13161\n",
        "plt.title('ridge 0.13161')\n",
        "plt.subplot(224)\n",
        "plt.plot(xgb_predictions, c=\"green\")  # 0.12167\n",
        "plt.title('xgb 0.12167')\n",
        "plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
        "plt.show()\n",
        "plt.subplot(111)\n",
        "plt.plot(predictions, c=\"red\")  # 0.12417\n",
        "plt.title('4 model vote 0.12417')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6K7whk1nimq"
      },
      "outputs": [],
      "source": [
        "submission = pd.DataFrame({\n",
        "        \"Id\": test_Id,\n",
        "        \"SalePrice\": lasso_predictions\n",
        "    })\n",
        "submission.to_csv(\"result/lasso_predictions_2_13.csv\", index=False)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "        \"Id\": test_Id,\n",
        "        \"SalePrice\": ridge_predictions\n",
        "    })\n",
        "submission.to_csv(\"result/ridge_predictions_2_13.csv\", index=False)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "        \"Id\": test_Id,\n",
        "        \"SalePrice\": elastic_net_predictions\n",
        "    })\n",
        "submission.to_csv(\"result/elastic_net_predictions_2_13.csv\", index=False)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "        \"Id\": test_Id,\n",
        "        \"SalePrice\": xgb_predictions\n",
        "    })\n",
        "submission.to_csv(\"result/xgb_predictions_2_13.csv\", index=False)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "        \"Id\": test_Id,\n",
        "        \"SalePrice\": predictions\n",
        "    })\n",
        "submission.to_csv(\"result/4_model_vote_predictions_2_13.csv\", index=False)\n",
        "\n",
        "print \"Done.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "3_7botovnimr"
      },
      "source": [
        "# Best Vote Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdMUqY1Unims"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LassoCV\n",
        "\n",
        "model_lasso = LassoCV(alphas = [1, 0.1, 0.001, 0.0005]).fit(train_X, train_Y)\n",
        "print rmse(model_lasso.predict(train_X), train_Y)\n",
        "lasso_predictions = model_lasso.predict(test_X)\n",
        "lasso_predictions = np.expm1(lasso_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgGcKSa5nimt"
      },
      "outputs": [],
      "source": [
        "predictions = (lasso_predictions + xgb_predictions) / 2\n",
        "submission = pd.DataFrame({\n",
        "        \"Id\": test_Id,\n",
        "        \"SalePrice\": predictions\n",
        "    })\n",
        "submission.to_csv(\"result/lasso_xgb_vote_predictions_2_13.csv\", index=False)\n",
        "\n",
        "print \"Done.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pcDtcEtnimt"
      },
      "outputs": [],
      "source": [
        "lasso_score = 1-0.12818\n",
        "xgb_score = 1-0.12167\n",
        "total_score = lasso_score + xgb_score\n",
        "predictions = (lasso_score / total_score) * lasso_predictions + \\\n",
        "              (xgb_score / total_score) * xgb_predictions\n",
        "            \n",
        "submission = pd.DataFrame({\n",
        "        \"Id\": test_Id,\n",
        "        \"SalePrice\": predictions\n",
        "    })\n",
        "submission.to_csv(\"result/lasso_xgb_weighted_vote_predictions_2_13.csv\", index=False)\n",
        "\n",
        "print \"Done.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bVzbzl3Enimu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "P-eLVM9unimT"
      ]
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}