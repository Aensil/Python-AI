{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BTWrldbtZgw"
      },
      "source": [
        "# **El Perceptrón**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PlayGROUND OF NEURAL NETWORKS\n",
        "#https://playground.tensorflow.org/"
      ],
      "metadata": {
        "id": "HeIvlIGks8IC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4H0pglG2teFa"
      },
      "source": [
        "https://spin.atomicobject.com/2014/06/24/gradient-descent-linear-regression/\n",
        "\n",
        "¿Cómo ocurre la propagacion inversa por medio del gradiente descendiente? Revisar el link\n",
        "\n",
        "Sugerencia: primero leer y entender la parte de la definición general (if __name__ == \"__main__\":) y despues entrar en el modelo del perceprtron (class NeuralNetwork())\n",
        "\n",
        "Abdel - 2022"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qZxAwNYtzqN"
      },
      "source": [
        "#Librerías\n",
        "from numpy import exp, array, random, dot"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ekws2kzIwhUf"
      },
      "source": [
        "###Definición del Perceptrón"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9vMFnGmt8ao"
      },
      "source": [
        "#Perceptrón\n",
        "class NeuralNetwork():\n",
        "    def __init__(self):\n",
        "        # Inicializar la semilla del generador aleatorio para que siempre de los mismos numeros\n",
        "        # cada vez que el programa corra\n",
        "        random.seed(1)\n",
        "\n",
        "        # Modelo de una sola neurona, con una conexion de salida y tres de entrada.\n",
        "        # asignamos pesos aleatorios a una matriz 3 x 1, con los valores en el rango -1 a 1\n",
        "        # y media 0.\n",
        "        self.synaptic_weights = 2 * random.random((3, 1)) - 1\n",
        "\n",
        "        self.E = [] #Errors per iteration\n",
        "\n",
        "    # La función sigmoidea, que describe una función en forma de s, es la función de activación.\n",
        "    # Nosotros hacemos pasar la suma de los pesos a través de dicha función para normalizarla entre 0 y 1 (porque eso es lo que esperamos) y así poder dar un resultado\n",
        "    def __tanh(self, x):\n",
        "        return (exp(x) - exp(-x)) / (exp(x) + exp(-x))\n",
        "\n",
        "    # La derivada de la función sigmoidea\n",
        "    # es el gradiente descendiente de la función sigmoidea\n",
        "    # Indica qué tanto \"le creemos\" a los pesos resultantes, revisar link.\n",
        "    def __tanh_derivative(self, x):\n",
        "        return 1 - (x**2)\n",
        "\n",
        "    # Entrenamos a la red neuronal a través de un proceso de prueba y error\n",
        "    # Ajustamos los pesos sinápticos en cada iteración\n",
        "    def train(self, training_set_inputs, training_set_outputs, number_of_training_iterations, learning_rate):\n",
        "        for iteration in range(number_of_training_iterations):\n",
        "            # Pasamos el conjunto de entrenamiento a través de la red neuronal (una única neurona).\n",
        "            output = self.think(training_set_inputs)\n",
        "\n",
        "            # Calculamos el error (La diferencia entre el valor que esperamos obtener realmente\n",
        "            # y la salida predicha).\n",
        "            error = training_set_outputs - output\n",
        "\n",
        "            #Promediando los errores\n",
        "            f = 0\n",
        "            for i in range(len(error)):\n",
        "              f = f + float(error[i])\n",
        "\n",
        "            f = f/len(error)\n",
        "            self.E.append(f) #Añade los errores a la lista\n",
        "\n",
        "\n",
        "            #Multiplicamos el error por el learning rate\n",
        "            error = error*learning_rate\n",
        "\n",
        "            # Multiplique el error por la entrada y de nuevo por el gradiente descendiente de la función sigmoidea.\n",
        "            # Esto significa que los pesos menos confiables se ajustan más (filtrado) \n",
        "            # Esto significa que las entradas, que son cero, no causan cambio a los pesos.\n",
        "            #--------------------------\n",
        "            adjustment = dot(training_set_inputs.T, error * self.__tanh_derivative(output))\n",
        "\n",
        "            # Ajustar los pesos.\n",
        "            self.synaptic_weights += adjustment\n",
        "\n",
        "    #Proceso de aprendizaje de la red neuronal:\n",
        "    def think(self, inputs):\n",
        "        # Pasamos las entradas a través de la red neuronal (una única neurona).\n",
        "        return self.__tanh(dot(inputs, self.synaptic_weights))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeESy5syweNb"
      },
      "source": [
        "###Clase Principal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0FY1SeMuCdO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a0f718c-631c-4a4c-eb53-257618c4494c"
      },
      "source": [
        "#Clase principal\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    #Inicialice una red neuronal de una sola neurona. Quizas no sea propiamente una red... \n",
        "    neural_network = NeuralNetwork()\n",
        "\n",
        "    print (\"Pesos sinapticos iniciales generados aleatoriamente: \")\n",
        "    print (neural_network.synaptic_weights)\n",
        "\n",
        "    # El conjunto de entrenamiento. Tenemos 4 ejemplos, cada uno consistente de tres valores de entrada con su respectiva salida (una salida)\n",
        "    training_set_inputs = array([[0, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 1],[0, 0, 0], [0, 1, 0],[1, 1, 0]])\n",
        "    training_set_outputs = array([[0, 1, 0, 0, 0, 0, 0]]).T\n",
        "  \n",
        "    #Number of epoch or Ciclys of learning\n",
        "    epoch = int(input('Number of Cycle: '))\n",
        "    learning_rate = float(input('learning rate: '))\n",
        "\n",
        "\n",
        "    # Entrene a la red neuronal usando un conjunto de entrenamiento.\n",
        "    # lo iteramos 10,000 veces, haciendo pequeños ajustes de pesos en cada iteración\n",
        "    neural_network.train(training_set_inputs, training_set_outputs, epoch, learning_rate)\n",
        "\n",
        "    print (\"Nuevos pesos sinapticos después del entremaniento: \")\n",
        "    print (neural_network.synaptic_weights)\n",
        "\n",
        "    # Pruebe la red neuronal con una situacion desconocida.\n",
        "    test = array([1, 0, 1])\n",
        "    print (\"Considerando las entradas: \")\n",
        "    print (test)\n",
        "    print (\"---------------------------\")\n",
        "    print (neural_network.think(test))         #100000 iterations - 0.25 learning rate\n",
        "\n",
        "    #NORMALIZATION\n",
        "    x = float(neural_network.think(test))\n",
        "    if x > 0.3:                                #The Hyperbolic tangent it's between -1 and 1\n",
        "      x = 1\n",
        "    else:\n",
        "      x = 0\n",
        "    print(\"---------------------------\")\n",
        "    print('The result is: ', x)\n",
        "\n",
        "    print(\"---------------------------\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pesos sinapticos iniciales generados aleatoriamente: \n",
            "[[-0.16595599]\n",
            " [ 0.44064899]\n",
            " [-0.99977125]]\n",
            "Number of Cycle: 10000\n",
            "learning rate: 0.1\n",
            "Nuevos pesos sinapticos después del entremaniento: \n",
            "[[0.2098857 ]\n",
            " [0.09248174]\n",
            " [0.09248174]]\n",
            "Considerando las entradas: \n",
            "[1 0 1]\n",
            "---------------------------\n",
            "[0.29347765]\n",
            "---------------------------\n",
            "The result is:  0\n",
            "---------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(neural_network.E, color=\"red\")     #Columnas a graficar y el color\n",
        "plt.ylabel(\"Errors\")                              #Nombre de los datos en Y\n",
        "plt.xlabel(\"Iterations\")                         #Nombre de los datos en X\n",
        "plt.show()                                    #Imprime la grafica\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "KxxwLFhoYFab",
        "outputId": "7f994f3e-2349-4f45-e8c8-bf0b018b737e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}